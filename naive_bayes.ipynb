{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 implement a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, wordlist):\n",
    "        self.wordlist = wordlist\n",
    "\n",
    "    def count_labels(self, data):\n",
    "        \"\"\"\n",
    "        Count the number of positive labels and negative labels.\n",
    "        Returns (a tuple or a numpy array of two elements):\n",
    "            * negative_count: a non-negative integer, which represents the number of negative labels (non-spam emails);\n",
    "            * positive_count: a non-negative integer, which represents the number of positive labels (spam emails).\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        count1=0\n",
    "        count0=0\n",
    "        for i in data:\n",
    "            if i[0]==1:\n",
    "                count1+=1\n",
    "            else:\n",
    "                count0+=1\n",
    "        return (count0,count1)   \n",
    "    \n",
    "\n",
    "    def count_words(self, wordlist, data):\n",
    "        \"\"\"\n",
    "        Count the number of times that each word appears in emails under a given label.\n",
    "        Returns (a numpy array):\n",
    "            * word_counts: a numpy array with shape (2, L), where L is the length of $wordlist,\n",
    "                - word_counts[0, i] represents the number of times that word $wordlist[i] appears in non-spam (negative) emails, and\n",
    "                - word_counts[1, i] represents the number of times that word $wordlist[i] appears in spam (positive) emails.\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        arr = np.zeros((2,len(wordlist)))\n",
    "        for i in range(len(wordlist)):\n",
    "            w = wordlist[i]\n",
    "            count0 = 0\n",
    "            count1 = 0\n",
    "            for j in data:\n",
    "                if w in j[1]:\n",
    "                    if j[0]==0:\n",
    "                        count0+=1\n",
    "                    else:\n",
    "                        count1+=1\n",
    "            arr[0,i]=count0\n",
    "            arr[1,i]=count1               \n",
    "        return arr\n",
    "\n",
    "    def calculate_probability(self, label_counts, word_counts):\n",
    "        \"\"\"\n",
    "        Calculate the probabilities, both the prior and likelihood.\n",
    "        Returns (a pair of numpy array):\n",
    "            * prior_probs: a numpy array with shape (2, ), only two elements, where\n",
    "                - prior_probs[0] is the prior probability of negative labels, and\n",
    "                - prior_probs[1] is the prior probability of positive labels.\n",
    "            * likelihood_probs: a numpy array with shape (2, L), where L is the length of the word list,\n",
    "                - likelihood_probs[0, i] represents the likelihood probability of the $i-th word in the word list, given that the email is non-spam (negative), and\n",
    "                - likelihood_probs[1, i] represents the likelihood probability of the $i-th word in the word list, given that the email is spam (positive).\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        prior_probs = np.zeros((2,))\n",
    "        prior_probs[0] = label_counts[0]/(label_counts[0]+label_counts[1])\n",
    "        prior_probs[1] = label_counts[1]/(label_counts[0]+label_counts[1])\n",
    "        \n",
    "        L = len(self.wordlist)\n",
    "        likelihood_probs = np.zeros((2,L))\n",
    "        for i in range(L):\n",
    "            likelihood_probs[0,i] = word_counts[0,i]/label_counts[0]\n",
    "            likelihood_probs[1,i] = word_counts[1,i]/label_counts[1]\n",
    "        return prior_probs, likelihood_probs\n",
    "    \n",
    "\n",
    "    def fit(self, data):\n",
    "        label_counts = self.count_labels(data)\n",
    "        word_counts = self.count_words(self.wordlist, data)\n",
    "\n",
    "        self.prior_probs, self.likelihood_probs = self.calculate_probability(label_counts, word_counts)\n",
    "\n",
    "        # TO AVOID NUMBER OVERFLOW here we use log probability instead.\n",
    "        self.log_prior_probs = np.log(self.prior_probs)\n",
    "#??????????????\n",
    "        self.log_likelihood_probs = np.dstack([np.log(1 - self.likelihood_probs), np.log(self.likelihood_probs)])\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict whether email $x is a spam or not.\n",
    "        Returns:\n",
    "            * y: a boolean value indicating whether $x is a spam or not.\n",
    "        \"\"\" \n",
    "        p0 = 1\n",
    "        p1 = 1\n",
    "        for w in x:\n",
    "            if w in self.wordlist:\n",
    "                index = self.wordlist.index(w)\n",
    "                if self.log_likelihood_probs[0][index][0]!=0:\n",
    "                    p0+=self.log_likelihood_probs[0][index][1]\n",
    "                if self.log_likelihood_probs[1][index][0]!=0:\n",
    "                    p1+=self.log_likelihood_probs[1][index][1]\n",
    "        p0+= self.log_prior_probs[0]\n",
    "        p1+= self.log_prior_probs[1]\n",
    "        if p1>=p0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Read the dataset from the file given by name $filename.\n",
    "    The returned object should be a list of pairs of data. In each pair: the first element is 1 (for spam emails) \n",
    "    or 0 (for non-spam emails), the second element is a list of words in the email.\n",
    "    The returned list: \n",
    "        [\n",
    "            (1 , ['a', 'b', 'c']),\n",
    "            (0, ['d', 'e', 'f']),\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    file = open(filename,\"r\")\n",
    "    line = file.readline()\n",
    "    lists = []\n",
    "    while len(line)!=0:\n",
    "        lst = line.rstrip(\"\\n\").split(\" \")\n",
    "        label = int(lst[0])\n",
    "        arr = lst[1:]\n",
    "        temp = (label,arr)\n",
    "        lists.append(temp)\n",
    "        line = file.readline()\n",
    "    return lists\n",
    "\n",
    "def split_train(original_train_data, size=4000):\n",
    "    return original_train_data[:size], original_train_data[size:]\n",
    "\n",
    "\n",
    "def create_wordlist(original_train_data, threshold=26):\n",
    "    \"\"\"\n",
    "    Create a word list from the original training set.\n",
    "    Only get a word if it appears in at least $threshold emails.\n",
    "    Returns:\n",
    "        * a python list containing all the words that occur in at least $threshold emails.\n",
    "    \"\"\"\n",
    "    dic = {}   \n",
    "    #dic = {'a':(2,True),'b':(1,False)...} \n",
    "    #if True, the word has not appeared in the text, if false, the word has been marked, so we skip it\n",
    "    for i in range(len(original_train_data)):\n",
    "        for j in range(len(original_train_data[i][1])):\n",
    "            if original_train_data[i][1][j] in dic:\n",
    "                if dic[original_train_data[i][1][j]][1]==True:\n",
    "                    temp = (dic[original_train_data[i][1][j]][0]+1,False)\n",
    "                    dic[original_train_data[i][1][j]] = temp\n",
    "            else:\n",
    "                dic[original_train_data[i][1][j]] = (1,False)\n",
    "        for w in dic.keys():   #initialize the markers\n",
    "            temp = (dic[w][0],True)\n",
    "            dic[w] = temp\n",
    "    arr = []\n",
    "    for w in dic.keys(): \n",
    "        if dic[w][0]>=threshold:\n",
    "            arr.append(w)        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold to determine whether to include a word in the dictionary/wordlist.\n",
    "# ie. only words with frequency higher than threshold are included\n",
    "THRESHOLD = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of words: 3048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-39dab0b1a316>:80: RuntimeWarning: divide by zero encountered in log\n",
      "  self.log_likelihood_probs = np.dstack([np.log(1 - self.likelihood_probs), np.log(self.likelihood_probs)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error, # =  131, % =  13.1000%.\n"
     ]
    }
   ],
   "source": [
    "original_train_data = read_data('spam_train.txt')\n",
    "\n",
    "\n",
    "# further split the data into a training set and a validation set\n",
    "train_data, val_data = split_train(original_train_data)\n",
    "\n",
    "\n",
    "# Create the word list.\n",
    "wordlist = create_wordlist(original_train_data, 26)\n",
    "print(\"Total # of words:\", len(wordlist))\n",
    "\n",
    "# fit the model using train_data\n",
    "model = Model(wordlist)\n",
    "model.fit(original_train_data)\n",
    "\n",
    "\n",
    "# TODO\n",
    "# calculate the error rate on val_data (when threshold=26)\n",
    "# print out the error rate\n",
    "\n",
    "\n",
    "error_count = sum([y != model.predict(x) for y, x in val_data])\n",
    "error_percentage = 100.0 * error_count / len(val_data)\n",
    "print(\"Validation error, # = {:>4d}, % = {:>8.4f}%.\".format(error_count, error_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 try different thresholds, find the optimal threshold (which gives minimum validation error), print out the test error at the optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_rate(model, data):    \n",
    "    error_count = sum([y != model.predict(x) for y, x in data])\n",
    "    return 100.0 * error_count / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = list(range(1, 35))\n",
    "train_error = []\n",
    "val_error = []\n",
    "test_error = []\n",
    "original_train_data = read_data('spam_train.txt')\n",
    "train_data, val_data = split_train(original_train_data)\n",
    "test_data = read_data('spam_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With threshold 1....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-39dab0b1a316>:80: RuntimeWarning: divide by zero encountered in log\n",
      "  self.log_likelihood_probs = np.dstack([np.log(1 - self.likelihood_probs), np.log(self.likelihood_probs)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:64.075 val:57.3 test:58.1 len(V)=65812\n",
      "time: 2032.6159002780914\n",
      "With threshold 2....\n",
      "train:57.4 val:57.3 test:53.5 len(V)=19298\n",
      "time: 814.350567817688\n",
      "With threshold 3....\n",
      "train:51.9 val:54.0 test:49.3 len(V)=12882\n",
      "time: 476.2333481311798\n",
      "With threshold 4....\n",
      "train:47.425 val:49.7 test:45.3 len(V)=10362\n",
      "time: 406.3313248157501\n",
      "With threshold 5....\n",
      "train:43.1 val:46.2 test:40.7 len(V)=8773\n",
      "time: 382.0371460914612\n",
      "With threshold 6....\n",
      "train:38.775 val:41.8 test:37.3 len(V)=7803\n",
      "time: 324.1410689353943\n",
      "With threshold 7....\n",
      "train:35.225 val:38.1 test:35.2 len(V)=7085\n",
      "time: 335.27117896080017\n",
      "With threshold 8....\n",
      "train:32.3 val:35.4 test:32.8 len(V)=6493\n",
      "time: 472.5269150733948\n",
      "With threshold 9....\n",
      "train:29.9 val:32.8 test:30.8 len(V)=5982\n",
      "time: 266.7581880092621\n",
      "With threshold 10....\n",
      "train:28.325 val:31.0 test:29.0 len(V)=5603\n",
      "time: 310.2769601345062\n",
      "With threshold 11....\n",
      "train:27.125 val:29.7 test:27.4 len(V)=5303\n",
      "time: 262.27193117141724\n",
      "With threshold 12....\n",
      "train:25.45 val:28.5 test:26.7 len(V)=4988\n",
      "time: 251.99764919281006\n",
      "With threshold 13....\n",
      "train:24.075 val:27.7 test:25.7 len(V)=4727\n",
      "time: 220.51197290420532\n",
      "With threshold 14....\n",
      "train:22.625 val:26.6 test:24.3 len(V)=4499\n",
      "time: 227.22172379493713\n",
      "With threshold 15....\n",
      "train:21.55 val:26.0 test:23.3 len(V)=4310\n",
      "time: 238.8168339729309\n",
      "With threshold 16....\n",
      "train:20.675 val:25.5 test:22.4 len(V)=4133\n",
      "time: 221.24450492858887\n",
      "With threshold 17....\n",
      "train:20.375 val:24.4 test:21.4 len(V)=3984\n",
      "time: 212.87284302711487\n",
      "With threshold 18....\n",
      "train:19.375 val:23.4 test:20.1 len(V)=3848\n",
      "time: 387.5352108478546\n",
      "With threshold 19....\n",
      "train:18.775 val:22.5 test:19.7 len(V)=3724\n",
      "time: 198.09013199806213\n",
      "With threshold 20....\n",
      "train:18.075 val:21.8 test:18.8 len(V)=3613\n",
      "time: 209.0738170146942\n",
      "With threshold 21....\n",
      "train:17.75 val:21.0 test:17.9 len(V)=3521\n",
      "time: 206.81291103363037\n",
      "With threshold 22....\n",
      "train:17.175 val:20.3 test:17.4 len(V)=3408\n",
      "time: 195.14100313186646\n",
      "With threshold 23....\n",
      "train:16.725 val:19.4 test:16.5 len(V)=3308\n",
      "time: 194.0149209499359\n",
      "With threshold 24....\n",
      "train:16.25 val:19.0 test:15.9 len(V)=3206\n",
      "time: 196.71227717399597\n",
      "With threshold 25....\n",
      "train:16.1 val:18.8 test:16.1 len(V)=3137\n",
      "time: 201.77573680877686\n",
      "With threshold 26....\n",
      "train:15.55 val:18.3 test:15.4 len(V)=3048\n",
      "time: 266.89168190956116\n",
      "With threshold 27....\n",
      "train:15.225 val:17.4 test:14.7 len(V)=2968\n",
      "time: 239.9481599330902\n",
      "With threshold 28....\n",
      "train:15.0 val:17.6 test:14.2 len(V)=2906\n",
      "time: 251.37281584739685\n",
      "With threshold 29....\n",
      "train:14.55 val:17.1 test:13.6 len(V)=2840\n",
      "time: 174.28085589408875\n",
      "With threshold 30....\n",
      "train:14.075 val:16.6 test:13.2 len(V)=2769\n",
      "time: 173.6036560535431\n",
      "With threshold 31....\n",
      "train:14.125 val:16.8 test:13.1 len(V)=2712\n",
      "time: 179.60882902145386\n",
      "With threshold 32....\n",
      "train:14.1 val:16.8 test:12.8 len(V)=2655\n",
      "time: 177.57079696655273\n",
      "With threshold 33....\n",
      "train:13.9 val:16.6 test:12.8 len(V)=2607\n",
      "time: 169.68380498886108\n",
      "With threshold 34....\n",
      "train:13.675 val:16.5 test:12.8 len(V)=2562\n",
      "time: 158.09156775474548\n"
     ]
    }
   ],
   "source": [
    "for th in thresholds:\n",
    "    print('With threshold {}....'.format(th))\n",
    "    time1 = time.time()\n",
    "\n",
    "    # vocabulary selection\n",
    "    wordlist = create_wordlist(original_train_data, th)\n",
    "\n",
    "    # fit model using the wordlist\n",
    "    model = Model(wordlist)\n",
    "    model.fit(train_data)\n",
    "\n",
    "    # compute classification error rates\n",
    "    err_train = compute_error_rate(model, train_data)\n",
    "    err_val = compute_error_rate(model, val_data)\n",
    "    err_test = compute_error_rate(model, test_data)\n",
    "\n",
    "    # store results for plotting\n",
    "    train_error.append(err_train)\n",
    "    val_error.append(err_val)\n",
    "    test_error.append(err_test)\n",
    "\n",
    "    time2 = time.time()\n",
    "    print(\"train:{} val:{} test:{} len(V)={}\".format(err_train, err_val, err_test, len(wordlist)))\n",
    "    print('time: {}'.format(time2 - time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (34,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-574e7e7b2eb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'validation error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2838\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2839\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2840\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2841\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \"\"\"\n\u001b[1;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (34,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training and validation error rate vs. the thresholds\n",
    "# choose the threshold with the minimal validation error rate and report the corresponding test error rate\n",
    "\n",
    "# TODO\n",
    "\n",
    "plt.plot(thresholds,train_error, label = 'training error')\n",
    "plt.plot(thresholds,val_error, label = 'validation error')\n",
    "plt.legend()\n",
    "opt=val_error.index(min(val_error))\n",
    "print('Best performance at validated threshold {} with test error rate {}.'.format(opt+1, val_error[opt]/len(val_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
