{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optical-supply",
   "metadata": {},
   "source": [
    "# Problem 3 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-judgment",
   "metadata": {},
   "source": [
    "## 3.1 implement a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, wordlist):\n",
    "        self.wordlist = wordlist\n",
    "\n",
    "    def count_labels(self, data):\n",
    "        \"\"\"\n",
    "        Count the number of positive labels and negative labels.\n",
    "        Returns (a tuple or a numpy array of two elements):\n",
    "            * negative_count: a non-negative integer, which represents the number of negative labels (non-spam emails);\n",
    "            * positive_count: a non-negative integer, which represents the number of positive labels (spam emails).\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def count_words(self, wordlist, data):\n",
    "        \"\"\"\n",
    "        Count the number of times that each word appears in emails under a given label.\n",
    "        Returns (a numpy array):\n",
    "            * word_counts: a numpy array with shape (2, L), where L is the length of $wordlist,\n",
    "                - word_counts[0, i] represents the number of times that word $wordlist[i] appears in non-spam (negative) emails, and\n",
    "                - word_counts[1, i] represents the number of times that word $wordlist[i] appears in spam (positive) emails.\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def calculate_probability(self, label_counts, word_counts):\n",
    "        \"\"\"\n",
    "        Calculate the probabilities, both the prior and likelihood.\n",
    "        Returns (a pair of numpy array):\n",
    "            * prior_probs: a numpy array with shape (2, ), only two elements, where\n",
    "                - prior_probs[0] is the prior probability of negative labels, and\n",
    "                - prior_probs[1] is the prior probability of positive labels.\n",
    "            * likelihood_probs: a numpy array with shape (2, L), where L is the length of the word list,\n",
    "                - likelihood_probs[0, i] represents the likelihood probability of the $i-th word in the word list, given that the email is non-spam (negative), and\n",
    "                - likelihood_probs[1, i] represents the likelihood probability of the $i-th word in the word list, given that the email is spam (positive).\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def fit(self, data):\n",
    "        label_counts = self.count_labels(data)\n",
    "        word_counts = self.count_words(self.wordlist, data)\n",
    "\n",
    "        self.prior_probs, self.likelihood_probs = self.calculate_probability(label_counts, word_counts)\n",
    "\n",
    "        # TO AVOID NUMBER OVERFLOW here we use log probability instead.\n",
    "        self.log_prior_probs = np.log(self.prior_probs)\n",
    "        self.log_likelihood_probs = np.dstack([np.log(1 - self.likelihood_probs), np.log(self.likelihood_probs)])\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict whether email $x is a spam or not.\n",
    "        Returns:\n",
    "            * y: a boolean value indicating whether $x is a spam or not.\n",
    "        \"\"\"        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Read the dataset from the file given by name $filename.\n",
    "    The returned object should be a list of pairs of data. In each pair: the first element is 1 (for spam emails) \n",
    "    or 0 (for non-spam emails), the second element is a list of words in the email.\n",
    "    The returned list: \n",
    "        [\n",
    "            (1 , ['a', 'b', 'c']),\n",
    "            (0, ['d', 'e', 'f']),\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def split_train(original_train_data, size=4000):\n",
    "    return original_train_data[:size], original_train_data[size:]\n",
    "\n",
    "\n",
    "def create_wordlist(original_train_data, threshold=26):\n",
    "    \"\"\"\n",
    "    Create a word list from the original training set.\n",
    "    Only get a word if it appears in at least $threshold emails.\n",
    "    Returns:\n",
    "        * a python list containing all the words that occur in at least $threshold emails.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold to determine whether to include a word in the dictionary/wordlist.\n",
    "# ie. only words with frequency higher than threshold are included\n",
    "THRESHOLD = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_data = read_data('spam_train.txt')\n",
    "\n",
    "# further split the data into a training set and a validation set\n",
    "train_data, val_data = split_train(original_train_data)\n",
    "\n",
    "# Create the word list.\n",
    "wordlist = create_wordlist(original_train_data, 26)\n",
    "print(\"Total # of words:\", len(wordlist))\n",
    "\n",
    "# fit the model using train_data\n",
    "model = Model(wordlist)\n",
    "model.fit(train_data)\n",
    "\n",
    "\n",
    "# TODO\n",
    "# calculate the error rate on val_data (when threshold=26)\n",
    "# print out the error rate\n",
    "\n",
    "# print(\"Validation error, # = {:>4d}, % = {:>8.4f}%.\".format(error_count, error_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-equipment",
   "metadata": {},
   "source": [
    "## 3.2 try different thresholds, find the optimal threshold (which gives minimum validation error), print out the test error at the optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_rate(model, data):\n",
    "    \n",
    "    error_count = sum([y != model.predict(x) for y, x in data])\n",
    "    return 100.0 * error_count / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = list(range(1, 35))\n",
    "train_error = []\n",
    "val_error = []\n",
    "test_error = []\n",
    "original_train_data = read_data('spam_train.txt')\n",
    "train_data, val_data = split_train(original_train_data)\n",
    "test_data = read_data('spam_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in thresholds:\n",
    "    print('With threshold {}....'.format(th))\n",
    "    time1 = time.time()\n",
    "\n",
    "    # vocabulary selection\n",
    "    wordlist = create_wordlist(original_train_data, th)\n",
    "\n",
    "    # fit model using the wordlist\n",
    "    model = Model(wordlist)\n",
    "    model.fit(train_data)\n",
    "\n",
    "    # compute classification error rates\n",
    "    err_train = compute_error_rate(model, train_data)\n",
    "    err_val = compute_error_rate(model, val_data)\n",
    "    err_test = compute_error_rate(model, test_data)\n",
    "\n",
    "    # store results for plotting\n",
    "    train_error.append(err_train)\n",
    "    val_error.append(err_val)\n",
    "    test_error.append(err_test)\n",
    "\n",
    "    time2 = time.time()\n",
    "    print(\"train:{} val:{} test:{} len(V)={}\".format(err_train, err_val, err_test, len(wordlist)))\n",
    "    print('time: {}'.format(time2 - time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training and validation error rate vs. the thresholds\n",
    "# choose the threshold with the minimal validation error rate and report the corresponding test error rate\n",
    "\n",
    "# TODO\n",
    "\n",
    "# print('Best performance at validated threshold {} with test error rate {}.'.format(opt, test_error[opt]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
